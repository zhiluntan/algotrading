{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Data Handling and Cleaning\n",
    "Author: Tan Zhi Lun  \n",
    "Contact: zhilun296@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is used to convert and parse data into a cleaner format for backtesting.\n",
    "\n",
    "In this section we will:\n",
    "1. Combine date & time column of forex 1 min OHLC data\n",
    "2. Pick out data from a specified period of time (e.g. picking out 2018 data)\n",
    "3. Convert timeframe of data (e.g. 1 min to 1 hr OHLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine Date & Time Column of Forex 1 Min OHLC Data\n",
    "\n",
    "The code below demonstrates the methodology used to combine the date and time column of forex 1 minute data. The original data (1986 to 2019) is saved in a csv file, and after the data is cleaned it is saved in a csv file once again using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Images/section1.jpg' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code used is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original  USDCAD\n",
      "         Date  Time    Open    High     Low   Close\n",
      "0  1986.12.01  1:00  1.3806  1.3806  1.3806  1.3806\n",
      "1  1986.12.01  1:01  1.3806  1.3806  1.3806  1.3806\n",
      "2  1986.12.01  1:02  1.3806  1.3806  1.3806  1.3806\n",
      "3  1986.12.01  1:03  1.3806  1.3806  1.3806  1.3806\n",
      "4  1986.12.01  1:04  1.3806  1.3806  1.3806  1.3806\n",
      " \n",
      "Cleaned  USDCAD\n",
      "                       Open    High     Low   Close\n",
      "datetime                                           \n",
      "1986-12-01 01:00:00  1.3806  1.3806  1.3806  1.3806\n",
      "1986-12-01 01:01:00  1.3806  1.3806  1.3806  1.3806\n",
      "1986-12-01 01:02:00  1.3806  1.3806  1.3806  1.3806\n",
      "1986-12-01 01:03:00  1.3806  1.3806  1.3806  1.3806\n",
      "1986-12-01 01:04:00  1.3806  1.3806  1.3806  1.3806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Choose pairs to clean\n",
    "pairs = (\"USDCAD\", \"AUDUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\")\n",
    "\n",
    "# In order to define rule for parsing dates\n",
    "def dateparse(d,t):\n",
    "    dt = d + \" \" + t\n",
    "    return datetime.datetime.strptime(dt, '%Y.%m.%d %H:%M')\n",
    "\n",
    "# To iterate for each pair, as well as clean up index column\n",
    "for i in pairs:\n",
    "    filename = i + \"_1_MT4.csv\"\n",
    "    df = pd.read_csv(filename, parse_dates={'datetime':['Date', 'Time']}, date_parser = dateparse)\n",
    "    df.index = df['datetime']\n",
    "    del df['datetime']\n",
    "    del df['Number']\n",
    "    # outname = i + \"_out.csv\"\n",
    "    # df.to_csv(outname)\n",
    "    \n",
    "    #Demonstration of handling using USDCAD\n",
    "    if i == \"USDCAD\":\n",
    "        df2 = pd.read_csv(filename)\n",
    "        del df2['Number']\n",
    "        print(\"Original \",i)\n",
    "        print(df2.head())\n",
    "        print(\" \")\n",
    "        print(\"Cleaned \",i)\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pick Out Data From Specified Period of Time\n",
    "\n",
    "In practice, data from too long ago is often unusable due to reasons such as regime shifts.\n",
    "\n",
    "Thus, the code below demonstrates the methodology used to pick out any period of time from the dataframe. For the example given the period chosen starts at 2nd Jan 2017 0830 hrs and ends at 31 Jan 2017 2359 hrs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Images/section2.jpg' width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDCAD\n",
      "                        Open     High      Low    Close\n",
      "datetime                                               \n",
      "2017-01-02 08:30:00  1.34416  1.34421  1.34412  1.34418\n",
      "2017-01-02 08:31:00  1.34430  1.34433  1.34416  1.34428\n",
      "2017-01-02 08:32:00  1.34418  1.34426  1.34415  1.34426\n",
      "2017-01-02 08:33:00  1.34426  1.34429  1.34414  1.34414\n",
      "2017-01-02 08:34:00  1.34414  1.34418  1.34412  1.34415\n",
      " \n",
      "AUDUSD\n",
      "                        Open     High      Low    Close\n",
      "datetime                                               \n",
      "2017-01-02 08:30:00  0.72069  0.72095  0.72028  0.72028\n",
      "2017-01-02 08:31:00  0.72037  0.72081  0.72037  0.72053\n",
      "2017-01-02 08:32:00  0.72053  0.72110  0.72052  0.72089\n",
      "2017-01-02 08:33:00  0.72089  0.72090  0.72076  0.72090\n",
      "2017-01-02 08:34:00  0.72089  0.72089  0.72089  0.72089\n",
      " \n",
      "GBPUSD\n",
      "                        Open     High      Low    Close\n",
      "datetime                                               \n",
      "2017-01-02 08:30:00  1.23431  1.23440  1.23431  1.23440\n",
      "2017-01-02 08:31:00  1.23440  1.23440  1.23438  1.23438\n",
      "2017-01-02 08:32:00  1.23438  1.23445  1.23432  1.23438\n",
      "2017-01-02 08:33:00  1.23438  1.23442  1.23433  1.23442\n",
      "2017-01-02 08:34:00  1.23443  1.23443  1.23441  1.23441\n",
      " \n",
      "USDJPY\n",
      "                        Open     High      Low    Close\n",
      "datetime                                               \n",
      "2017-01-02 08:30:00  116.952  116.952  116.952  116.952\n",
      "2017-01-02 08:31:00  116.952  116.953  116.952  116.953\n",
      "2017-01-02 08:32:00  116.953  117.026  116.953  117.026\n",
      "2017-01-02 08:33:00  117.022  117.027  117.022  117.027\n",
      "2017-01-02 08:34:00  117.027  117.032  117.027  117.032\n",
      " \n",
      "USDCHF\n",
      "                        Open     High      Low    Close\n",
      "datetime                                               \n",
      "2017-01-02 08:30:00  1.01847  1.01883  1.01825  1.01829\n",
      "2017-01-02 08:31:00  1.01832  1.01899  1.01832  1.01877\n",
      "2017-01-02 08:32:00  1.01878  1.01924  1.01875  1.01905\n",
      "2017-01-02 08:33:00  1.01892  1.01908  1.01878  1.01905\n",
      "2017-01-02 08:34:00  1.01894  1.01916  1.01877  1.01883\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define pairs that are to be cleaned\n",
    "pairs = (\"USDCAD\", \"AUDUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\")\n",
    "\n",
    "# Choose starting and end date\n",
    "year = 2017\n",
    "startdate = datetime(year,1,2,8,30)\n",
    "enddate = datetime(year,1,31,23,59)\n",
    "\n",
    "# Load pairs\n",
    "for i in pairs:\n",
    "    filename = i + '_out.csv'\n",
    "    outfile = i + '_out_2017.csv'\n",
    "    \n",
    "    # Set index column to datetime and parse by using to datetime, otherwise str wont be recognized for < & >\n",
    "    df = pd.read_csv(filename, index_col='datetime')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    del df['Number']\n",
    "    \n",
    "    # sdf for ranging purposes, in case certain years dont start on 1st Jan etc\n",
    "    sdf = (df.index>=startdate) & (df.index<=enddate)\n",
    "    \n",
    "    # loc by mask\n",
    "    df2 = df.loc[sdf]\n",
    "    \n",
    "    # Output to csv file\n",
    "    # df2.to_csv(outfile, index = 'datetime')\n",
    "    \n",
    "    print(i)\n",
    "    print(df2.head())\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Timeframe of Data\n",
    "\n",
    "In practice, different timeframes can be used for signal generation, e.g. higher timeframe data would better show the big picture trend.\n",
    "\n",
    "The code below demonstrates the methodology used combine the lower timeframe OHLC data. For the example given it combines 1 minute data into 5 minute data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Images/section3.jpg' width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        datetime     Open     High      Low    Close\n",
      "0  2/1/2018 0:00  1.20126  1.20126  1.20097  1.20103\n",
      "1  2/1/2018 0:01  1.20103  1.20105  1.19998  1.20048\n",
      "2  2/1/2018 0:02  1.20048  1.20057  1.19998  1.20043\n",
      "3  2/1/2018 0:03  1.20046  1.20076  1.20035  1.20062\n",
      "4  2/1/2018 0:04  1.20061  1.20070  1.20051  1.20065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "minutes = 5\n",
    "filename = \"eurusd_out_2018.csv\"\n",
    "outname = \"eurusd_out_2018_5mins.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(filename,index_col= False) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.20126\n",
      "5     1.20100\n",
      "10    1.20144\n",
      "15    1.20153\n",
      "20    1.20133\n",
      "25    1.20138\n",
      "Name: High, dtype: float64\n",
      "0     1.19998\n",
      "5     1.19970\n",
      "10    1.20077\n",
      "15    1.20128\n",
      "20    1.20090\n",
      "25    1.20106\n",
      "Name: Low, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df5=df.copy()\n",
    "df6=df.copy()\n",
    "\n",
    "for i in df.index:\n",
    "    n = math.floor(i/minutes) * minutes\n",
    "    n2 = (n + minutes -1)\n",
    "    df5.loc[i,'High'] = df.loc[n:n2,'High'].max()\n",
    "\n",
    "for i in df.index:\n",
    "    n = math.floor(i/minutes) * minutes\n",
    "    n2 = (n + minutes -1)\n",
    "    df6.loc[i,'Low'] = df.loc[n:n2,'Low'].min()\n",
    "\n",
    "df5 = df5.iloc[::minutes]['High']\n",
    "df6 = df6.iloc[::minutes]['Low']\n",
    "print(df5)\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open     High      Low      Low    Close\n",
      "datetime                                                  \n",
      "2/1/2018 0:00  1.20126  1.20126  1.19998  1.19998  1.20065\n",
      "2/1/2018 0:05  1.20067  1.20100  1.19970  1.19970  1.20086\n",
      "2/1/2018 0:10  1.20085  1.20144  1.20077  1.20077  1.20144\n",
      "2/1/2018 0:15  1.20140  1.20153  1.20128  1.20128  1.20134\n",
      "2/1/2018 0:20  1.20131  1.20133  1.20090  1.20090  1.20113\n"
     ]
    }
   ],
   "source": [
    "# Slicing the dataframes such that they can be combined later on\n",
    "df2 = df.iloc[::minutes]\n",
    "df3 = df.iloc[(minutes-1)::minutes]['Close']\n",
    "df2 = df2.drop(['High'], axis = 1)\n",
    "df2 = df2.drop(['Low'], axis = 1)\n",
    "df2 = df2.drop(['Close'], axis = 1)\n",
    "\n",
    "# Reset the index such that the dataframes can be merged accordingly\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df5 = df5.reset_index(drop=True)\n",
    "df6 = df6.reset_index(drop=True)\n",
    "df4 = pd.merge(df2, df5, left_index = True, right_index= True)\n",
    "df4 = pd.merge(df4, df6, left_index = True, right_index= True)\n",
    "df4 = pd.merge(df4, df3, left_index = True, right_index= True)\n",
    "\n",
    "# Rearranging\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[:4] + [cols[-2]] + [cols[-1]]\n",
    "df4 = df4[cols]\n",
    "\n",
    "# Resetting the index\n",
    "df4.index = df4['datetime']\n",
    "del df4['datetime']\n",
    "df4.to_csv(outname,index='datetime')\n",
    "\n",
    "print(df4.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
